{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32933228#1700177#1_2</td>\n",
       "      <td>I reccomend the fried pork dumplings[comma] th...</td>\n",
       "      <td>fried rice</td>\n",
       "      <td>71--81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35820984#608922#3_0</td>\n",
       "      <td>The staff is very sharp and they look good too.</td>\n",
       "      <td>staff</td>\n",
       "      <td>4--9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35170181#0#5_1</td>\n",
       "      <td>The best dessert[comma] a chocolate and peanut...</td>\n",
       "      <td>chocolate and peanut butter tart</td>\n",
       "      <td>20--52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33067279#1612676#1_1</td>\n",
       "      <td>The food was very good and I was pleasantly su...</td>\n",
       "      <td>vegan options</td>\n",
       "      <td>69--82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32882616#562969#3_0</td>\n",
       "      <td>I never had an orange donut before so I gave i...</td>\n",
       "      <td>orange donut</td>\n",
       "      <td>15--27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             example_id                                               text  \\\n",
       "0  32933228#1700177#1_2  I reccomend the fried pork dumplings[comma] th...   \n",
       "1   35820984#608922#3_0    The staff is very sharp and they look good too.   \n",
       "2        35170181#0#5_1  The best dessert[comma] a chocolate and peanut...   \n",
       "3  33067279#1612676#1_1  The food was very good and I was pleasantly su...   \n",
       "4   32882616#562969#3_0  I never had an orange donut before so I gave i...   \n",
       "\n",
       "                        aspect_term  term_location  \n",
       "0                        fried rice         71--81  \n",
       "1                             staff           4--9  \n",
       "2  chocolate and peanut butter tart         20--52  \n",
       "3                     vegan options         69--82  \n",
       "4                      orange donut         15--27  "
      ]
     },
     "execution_count": 1444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "#test 1 - \"Project-2_Test_Data/Data-1_test.csv\"\n",
    "import pandas as pd\n",
    "train_file_path = \"Project-2_Test_Data/Data-2_test.csv\"\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 4)"
      ]
     },
     "execution_count": 1445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' class'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1446-7654da360e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclass_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' class'"
     ]
    }
   ],
   "source": [
    "class_value = train_data[' class']\n",
    "class_value.describe()\n",
    "Y = class_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602,)"
      ]
     },
     "execution_count": 1440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2164\n",
       "-1     805\n",
       " 0     633\n",
       "Name:  class, dtype: int64"
      ]
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fried rice</td>\n",
       "      <td>71--81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>staff</td>\n",
       "      <td>4--9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chocolate and peanut butter tart</td>\n",
       "      <td>20--52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vegan options</td>\n",
       "      <td>69--82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orange donut</td>\n",
       "      <td>15--27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        aspect_term  term_location\n",
       "0                        fried rice         71--81\n",
       "1                             staff           4--9\n",
       "2  chocolate and peanut butter tart         20--52\n",
       "3                     vegan options         69--82\n",
       "4                      orange donut         15--27"
      ]
     },
     "execution_count": 1447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "example_ids = train_data['example_id']\n",
    "X = train_data.drop(['example_id',\" text\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training bigram tagger\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def build_backoff_tagger(train_sents):\n",
    "    t0 = nltk.DefaultTagger('NN')\n",
    "    t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "    t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_tagger = build_backoff_tagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125751765470128"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = train_data[\" text\"]\n",
    "new_text=[]\n",
    "for idx,text_record in enumerate(text_data):\n",
    "    aspect_loc = train_data.loc[idx,\" term_location\"]\n",
    "    locations = aspect_loc.split(\"--\")\n",
    "    current_text = text_data[idx].replace(\"[comma]\", \",\")\n",
    "    #current_text = current_text[:int(locations[0])] + \"<aspect>\" + current_text[int(locations[1]):]\n",
    "    new_text.append([current_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_text_aspect=[]\n",
    "for idx,text_record in enumerate(new_text):\n",
    "    aspect_loc = train_data.loc[idx,\" term_location\"]\n",
    "    locations = aspect_loc.split(\"--\")\n",
    "    current_text = text_record[0]\n",
    "    current_text = current_text[:int(locations[0])] + \"<aspect>\" + current_text[int(locations[1]):]\n",
    "    new_text_aspect.append(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting words in context 0f 5 from target term\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "sent_list=[]\n",
    "\n",
    "remove_list = [\",\",\".\",\".)\",\"..)\",\").\",\"?\",\"!\"]\n",
    "    \n",
    "    \n",
    "for idx,text_word in enumerate(new_text_aspect):\n",
    "    locations = train_data.loc[idx,\" term_location\"].split(\"--\")\n",
    "    sent = text_word\n",
    "    sent_left = sent[:int(locations[0])]\n",
    "    #token_left = nltk.word_tokenize(sent_left)\n",
    "    #print(token_left)\n",
    "    #bigram_left = nltk.bigrams(token_left)\n",
    "    #bigram_left = *map(' '.join, bigrm)\n",
    "    sent_right = sent[int(locations[0])+8:]\n",
    "    #print(sent_right)\n",
    "    \n",
    "    #token_right = nltk.word_tokenize(sent_right)\n",
    "    if sent_right not in remove_list:\n",
    "        sent_surf = ' '.join(sent_left.split()[-5:])+' '+' '.join(sent_right.split()[:5])\n",
    "    else:\n",
    "        sent_surf = ' '.join(sent_left.split()[-5:])\n",
    "    #print(sent_surf)\n",
    "    sent_list.append([sent_surf])\n",
    "    #bigrm_right = [b for b in nltk.bigrams(token_right)]\n",
    "    #bigrm_right = *map(' '.join, bigrm)\n",
    "    #print(bigrm_right)\n",
    "    #sent_left_words = ngrams(token_left,2)\n",
    "    #sent_right_words = ngrams(sent_right,1)\n",
    "    #words = sent_left_words[-3:] + sent_right_words[:3]\n",
    "    #context_word.append(words)\n",
    "    #print(sent_left_words)\n",
    "#print(context_word)\n",
    "#print(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer, WordPunctTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "features=[]\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "for line in sent_list:\n",
    "    #tokenizer = WordPunctTokenizer()\n",
    "    tokens = nltk.word_tokenize(line[0])\n",
    "    #stemmer = PorterStemmer()\n",
    "    bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "    bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)\n",
    "    #bigrams = ngrams(line,2)\n",
    "    for bigram_tuple in bigrams:\n",
    "        x = \"%s %s\" % bigram_tuple\n",
    "        tokens.append(x)\n",
    "    \n",
    "    #result = [b for b in nltk.bigrams(line) if b[0] not in stops and b[1] not in stops]\n",
    "\n",
    "    result = [' '.join([w for w in x.split()]) for x in tokens if x.lower() not in stops and len(x) > 8]\n",
    "    features.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_main=[]\n",
    "for f in features:\n",
    "    if f:\n",
    "        feature_main.append(f)\n",
    "        \n",
    "        \n",
    "vocab_list=[]\n",
    "for f in features:\n",
    "    for ele in f:\n",
    "        vocab_list.append(ele)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "vocab_list_set = set(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_uni=[]\n",
    "stop_list = stopwords.words('english') +['.',',',')','?','!','(','-',':','The','I','It','We',\"'\",'They','My','But','us']\n",
    "\n",
    "stops = set(stop_list)\n",
    "for line in sent_list:\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = nltk.word_tokenize(line[0])\n",
    "    #print(tokens)\n",
    "    #stemmer = PorterStemmer()\n",
    "    #bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "    #bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)\n",
    "    #bigrams = ngrams(line,2)\n",
    "    #for bigram_tuple in bigrams:\n",
    "    #    x = \"%s %s\" % bigram_tuple\n",
    "    #    tokens.append(x)\n",
    "    \n",
    "    #result = [b for b in nltk.bigrams(line) if b[0] not in stops and b[1] not in stops]\n",
    "    new_token = []\n",
    "    for token in tokens:\n",
    "        if token not in stops:\n",
    "            new_token.append(token)\n",
    "    features_uni.append(new_token)\n",
    "    #if tokens not in stops:\n",
    "    #    features_uni.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list_uni=[]\n",
    "for f in features_uni:\n",
    "    for ele in f:\n",
    "        vocab_list_uni.append(ele)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "vocab_list_set_uni = set(vocab_list_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_uni\n",
    "#vocab_list_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame({'text':new_text_aspect})\n",
    "#print (text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uni_df = pd.DataFrame(columns =vocab_list_set_uni )\n",
    "import numpy as np\n",
    "uni_df = pd.DataFrame(0, index=np.arange(X.shape[0]), columns =vocab_list_set_uni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1474)"
      ]
     },
     "execution_count": 1459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(vocabulary=vocab_list_set)\n",
    "X_train_bag = count_vect.fit_transform(text_df[\"text\"])\n",
    "X_term_freq = pd.DataFrame(X_train_bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with sum less than 25\n",
    "cols_with_less_than_25 = [col for col in X_term_freq.columns \n",
    "                                 if abs(X_term_freq[col].sum()) < 1]\n",
    "reduced_X_train = X_term_freq.drop(cols_with_less_than_25, axis=1)\n",
    "#reduced_X_val  = val_X.drop(cols_with_missing, axis=1)\n",
    "#print(\"Mean Absolute Error from dropping columns with Missing Values:\")\n",
    "#print(getScore(reduced_X_train, train_Y,reduced_X_val,  val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py:3846: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = op(self.values, np.asarray(other))\n"
     ]
    }
   ],
   "source": [
    "#dropping columns with stop words\n",
    "stop_list = stopwords.words('english')\n",
    "cols_with_stop_words = [col for col in reduced_X_train.columns \n",
    "                                 if reduced_X_train.columns in stop_list ]\n",
    "reduced_X_train_without_stops = reduced_X_train.drop(cols_with_stop_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_X_train_without_stops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer, WordPunctTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "features_uni_tagged=[]\n",
    "#stop_list = stopwords.words('english') +['.',',',')','?','!','(','-',':','The','I','It','We',\"'\",'They','My','But','us']\n",
    "\n",
    "#stops = set(stop_list)\n",
    "for line in sent_list:\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = nltk.word_tokenize(line[0])\n",
    "    #print(tokens)\n",
    "    #stemmer = PorterStemmer()\n",
    "    #bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "    #bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)\n",
    "    #bigrams = ngrams(line,2)\n",
    "    #for bigram_tuple in bigrams:\n",
    "    #    x = \"%s %s\" % bigram_tuple\n",
    "    #    tokens.append(x)\n",
    "    tagged_tokens = ngram_tagger.tag(tokens)\n",
    "    #result = [b for b in nltk.bigrams(line) if b[0] not in stops and b[1] not in stops]\n",
    "    #new_token = []\n",
    "    #for token in tokens:\n",
    "        #if token not in stops:\n",
    "     #       new_token.append(token)\n",
    "    features_uni_tagged.append(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tagged_Sent=[]\n",
    "for feature in features_uni_tagged:\n",
    "    sent = \"\"\n",
    "    for tuples in feature:\n",
    "        sent = sent +\" \" +tuples[0]+\"_\"+tuples[1]\n",
    "    \n",
    "    new_tagged_Sent.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df_tagged = pd.DataFrame({'text_tagged':new_tagged_Sent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_df_tagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words with pos tage\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_bag_tagged = count_vect.fit_transform(text_df_tagged[\"text_tagged\"])\n",
    "X_term_freq_tagged = pd.DataFrame(X_train_bag_tagged.toarray(),columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_bag_tagged)\n",
    "#X_train_tfidf.shape\n",
    "X_tfidf_tagged = pd.DataFrame(X_train_tfidf.toarray(),columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with sum less than 2\n",
    "cols_with_less_than_25 = [col for col in X_tfidf_tagged.columns \n",
    "                                 if abs(X_tfidf_tagged[col].sum()) < 2]\n",
    "reduced_X_train_tagged = X_tfidf_tagged.drop(cols_with_less_than_25, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_X_train_tagged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_X_train_tagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize as WordTokenizer\n",
    "\n",
    "def word_tokenizer(data, col):\n",
    "    token=[]\n",
    "    for item in data[col]:\n",
    "         token.append(WordTokenizer(item))\n",
    "\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token = word_tokenizer(text_df, \"text\")\n",
    "#df.insert(index, 'token_column', token)\n",
    "#print(token)\n",
    "#tokenize_data = pd.DataFrame(token)\n",
    "#word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize_data.head()\n",
    "#word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/noman/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/noman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'accompany',\n",
       " 'your',\n",
       " '<',\n",
       " 'aspect',\n",
       " '>',\n",
       " 'with',\n",
       " 'one',\n",
       " 'of',\n",
       " 'their',\n",
       " 'fresh',\n",
       " 'juice',\n",
       " 'concoctions',\n",
       " '.']"
      ]
     },
     "execution_count": 1478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=['aspect','<','>','is','the','of','for','and','.',',']\n",
    "word_token_reduced=[]\n",
    "for token in word_token:\n",
    "    new_token =  [x for x in token if x not in stop_words]\n",
    "    word_token_reduced.append(new_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Be',\n",
       " 'sure',\n",
       " 'to',\n",
       " 'accompany',\n",
       " 'your',\n",
       " 'with',\n",
       " 'one',\n",
       " 'their',\n",
       " 'fresh',\n",
       " 'juice',\n",
       " 'concoctions']"
      ]
     },
     "execution_count": 1480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token_reduced[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polarity shifter\n",
    "negWords = ['no', 'not', 'never', \"n't\"]\n",
    "def polarityShifter(word, index, negList):\n",
    "    if(word in negWords):\n",
    "        negList.append(index + 1)\n",
    "        negList.append(index + 2)\n",
    "    \n",
    "    return negList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def sentiWeights(words):\n",
    "    tagged_word = []\n",
    "    tagged = pos_tag(words)\n",
    "    #print(tagged)\n",
    "    #sentiment = 0.0\n",
    "    idx=-1\n",
    "    for word, tag in tagged:\n",
    "        sentiment = 0.0\n",
    "        negIndex = []\n",
    "        prevIndex = -1\n",
    "        idx = idx + 1 \n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,wn.VERB):\n",
    "            continue\n",
    "\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            continue\n",
    "\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "\n",
    "        # Take the first sense, the most common\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        negIndex = polarityShifter(word, idx, negIndex)\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        if(idx in negIndex and prevIndex != idx - 1):\n",
    "            prevIndex = idx\n",
    "            sentiment *= -1\n",
    "        tagged_word.append([word,sentiment,idx])\n",
    "        \n",
    "    return tagged_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_score_word = [] \n",
    "for token in word_token_reduced:\n",
    "    #print(token)\n",
    "    sent_score_word.append(sentiWeights(token))\n",
    "#print(sent_score_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fried', 0.0, 2], ['pork', 0.0, 3], ['dumplings', 0.0, 4]]"
      ]
     },
     "execution_count": 1484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tagged_word\n",
    "sent_score_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 1485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_score_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_token_reduced\n",
    "def getScoreForSentiments(feature_columns_sentiword,sent_score_word):\n",
    "    my_df= []\n",
    "    for senti in sent_score_word:\n",
    "        number_of_pos = 0\n",
    "        number_of_neg = 0\n",
    "        sum_of_scores = 0\n",
    "        maximum_token_score = 0\n",
    "        minimum_token_score = 0\n",
    "        for se in senti:\n",
    "            if se[1] > 0:\n",
    "                number_of_pos = number_of_pos+1\n",
    "\n",
    "            if se[1] < 0:\n",
    "                number_of_neg = number_of_neg+1\n",
    "\n",
    "            sum_of_scores = sum_of_scores + se[1]\n",
    "\n",
    "            if se[1] > maximum_token_score:\n",
    "                maximum_token_score = se[1]\n",
    "\n",
    "            if se[1] < minimum_token_score:\n",
    "                minimum_token_score = se[1]\n",
    "\n",
    "        #print(number_of_pos)\n",
    "\n",
    "        d = {\n",
    "            feature_columns_sentiword[0] : number_of_pos,  \n",
    "            feature_columns_sentiword[1] : number_of_neg,\n",
    "            feature_columns_sentiword[2] : sum_of_scores,\n",
    "            feature_columns_sentiword[3] : maximum_token_score,\n",
    "            feature_columns_sentiword[4] : minimum_token_score\n",
    "        }\n",
    "        my_df.append(d)\n",
    "\n",
    "    my_df = pd.DataFrame(my_df)\n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bing liu's opinion lexicon - negative words\n",
    "f = open('opinion-lexicon-English/negative-words.txt', 'r',encoding = \"ISO-8859-1\")\n",
    "negative_words_liu = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('opinion-lexicon-English/positive-words.txt', 'r',encoding = \"ISO-8859-1\")\n",
    "positive_words_liu = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative_words_liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiWeightsLiu(words):\n",
    "    tagged_word = []\n",
    "    tagged = pos_tag(words)\n",
    "    #print(tagged)\n",
    "    #sentiment = 0.0\n",
    "    idx=-1\n",
    "    for word, tag in tagged:\n",
    "        sentiment = 0.0\n",
    "        negIndex = []\n",
    "        prevIndex = -1\n",
    "        idx = idx + 1\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,wn.VERB):\n",
    "            continue\n",
    "\n",
    "        if word in positive_words_liu:\n",
    "            sentiment = 1.0\n",
    "        if word in negative_words_liu:\n",
    "            sentiment = -1.0\n",
    "            \n",
    "        negIndex = polarityShifter(word, idx, negIndex)\n",
    "\n",
    "        if(idx in negIndex and prevIndex != idx - 1):\n",
    "            prevIndex = idx\n",
    "            sentiment *= -1\n",
    "            \n",
    "        tagged_word.append([word,sentiment,idx])\n",
    "        \n",
    "    return tagged_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning weights on basis of liu's opinion lexicon\n",
    "\n",
    "sent_score_word_liu = [] \n",
    "for token in word_token_reduced:\n",
    "    #print(token)\n",
    "    sent_score_word_liu.append(sentiWeightsLiu(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['very', 0.0, 1],\n",
       " ['sharp', 1.0, 2],\n",
       " ['look', 0.0, 4],\n",
       " ['good', 1.0, 5],\n",
       " ['too', 0.0, 6]]"
      ]
     },
     "execution_count": 1492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score_word_liu[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_locations_tokens = []\n",
    "for word_ in word_token:\n",
    "    aspect_locations_tokens.append(word_.index(\"aspect\")-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_score_word_liu_new = []\n",
    "for idx,sent_liu in enumerate(sent_score_word_liu):\n",
    "    start_range = aspect_locations_tokens[idx]-3\n",
    "    end_range = aspect_locations_tokens[idx]+3\n",
    "    sent_new =[]\n",
    "    for sent in sent_liu:\n",
    "        if sent[2] >= start_range and sent[2] <= end_range:\n",
    "            sent[1] = sent[1] * 2\n",
    "        sent_new.append(sent)\n",
    "    sent_score_word_liu_new.append(sent_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_score_word_new = []\n",
    "for idx,sent_senti in enumerate(sent_score_word):\n",
    "    start_range = aspect_locations_tokens[idx]-3\n",
    "    end_range = aspect_locations_tokens[idx]+3\n",
    "    sent_new =[]\n",
    "    for sent in sent_senti:\n",
    "        if sent[2] >= start_range and sent[2] <= end_range:\n",
    "            sent[1] = sent[1] * 2\n",
    "        sent_new.append(sent)\n",
    "    sent_score_word_new.append(sent_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fried', 0.0, 2], ['pork', 0.0, 3], ['dumplings', 0.0, 4]]"
      ]
     },
     "execution_count": 1496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score_word_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['best', 2.0, 1],\n",
       " ['dessert', 0.0, 2],\n",
       " [\"n't\", 0.0, 4],\n",
       " ['particularly', 0.0, 5],\n",
       " ['Hawaiian', 0.0, 6],\n",
       " [\"'s\", 0.0, 9],\n",
       " ['small', 0.0, 11],\n",
       " ['world', 0.0, 12],\n",
       " ['comes', 0.0, 15],\n",
       " ['sweets', 0.0, 17]]"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score_word_liu_new[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['best', 2.0, 1],\n",
       " ['dessert', 0.0, 2],\n",
       " [\"n't\", 0.0, 4],\n",
       " ['particularly', 0.0, 5],\n",
       " ['Hawaiian', 0.0, 6],\n",
       " [\"'s\", 0.0, 9],\n",
       " ['small', 0.0, 11],\n",
       " ['world', 0.0, 12],\n",
       " ['comes', 0.0, 15],\n",
       " ['sweets', 0.0, 17]]"
      ]
     },
     "execution_count": 1498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score_word_liu[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpqa lexicon\n",
    "f = open('mpqa/mpqa.txt', 'r',encoding = \"ISO-8859-1\")\n",
    "mpqa_lines = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpqa_sent_score_word = []\n",
    "for mpqa in mpqa_lines:\n",
    "    mpqas = mpqa.split(\" \")\n",
    "    mpqa_types = mpqas[0].split(\"=\")\n",
    "    mpqa_type = mpqa_types[1]\n",
    "    mpqa_words = mpqas[2].split(\"=\")\n",
    "    mpqa_word = mpqa_words[1]\n",
    "    #print(mpqas)\n",
    "    #print(mpqas[5])\n",
    "    mpqa_polarities = mpqas[5].split(\"=\")\n",
    "    mpqa_polarity = mpqa_polarities[1]\n",
    "    score = 0.0\n",
    "    if mpqa_polarity == \"negative\":\n",
    "        if mpqa_type == \"weaksubj\":\n",
    "            score = -0.5\n",
    "        else:\n",
    "            score = -1.0\n",
    "            \n",
    "    if mpqa_polarity == \"positive\":\n",
    "        if mpqa_type == \"weaksubj\":\n",
    "            score = 0.5\n",
    "        else:\n",
    "            score = 1.0\n",
    "    \n",
    "    mpqa_sent_score_word.append([mpqa_word,score])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abasement', -1.0]"
      ]
     },
     "execution_count": 1501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpqa_sent_score_word[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mpqa_w in mpqa_sent_score_word:\n",
    "    if 'be' == mpqa_w[0]:\n",
    "        print(mpqa_w[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiWeightsMpqa(words):\n",
    "    tagged_word = []\n",
    "    tagged = pos_tag(words)\n",
    "    #print(tagged)\n",
    "    \n",
    "    idx=-1\n",
    "    for word, tag in tagged:\n",
    "        sentiment = 0.0\n",
    "        negIndex = []\n",
    "        prevIndex = -1\n",
    "        idx = idx + 1\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,wn.VERB):\n",
    "            continue\n",
    "\n",
    "        for mpqa_w in mpqa_sent_score_word:\n",
    "            if word == mpqa_w[0]:\n",
    "                sentiment = mpqa_w[1]\n",
    "                break\n",
    "        \n",
    "        negIndex = polarityShifter(word, idx, negIndex)\n",
    "\n",
    "        if(idx in negIndex and prevIndex != idx - 1):\n",
    "            prevIndex = idx\n",
    "            sentiment *= -1\n",
    "            \n",
    "        tagged_word.append([word,sentiment,idx])\n",
    "        \n",
    "    return tagged_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_score_word_mpqa = [] \n",
    "for token in word_token_reduced:\n",
    "    #print(token)\n",
    "    sent_score_word_mpqa.append(sentiWeightsMpqa(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['never', 0.0, 1],\n",
       " ['had', 0.0, 2],\n",
       " ['so', 0.0, 5],\n",
       " ['gave', 0.0, 7],\n",
       " ['shot', 0.0, 10]]"
      ]
     },
     "execution_count": 1505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_score_word_mpqa[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating unigram dataframe with weighted sentiment scores of mpqa\n",
    "\n",
    "for idx,sent_word_list in enumerate(sent_score_word_mpqa):\n",
    "    for sent_word in sent_word_list:\n",
    "        if sent_word[0] in uni_df.columns:\n",
    "            uni_df.loc[idx,sent_word[0]] = sent_word[1]\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1474)"
      ]
     },
     "execution_count": 1507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating unigram dataframe with weighted sentiment scores of liu\n",
    "\n",
    "for idx,sent_word_list in enumerate(sent_score_word_liu):\n",
    "    for sent_word in sent_word_list:\n",
    "        if sent_word[0] in uni_df.columns:\n",
    "            uni_df.loc[idx,sent_word[0]] = uni_df.loc[idx,sent_word[0]] + sent_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating unigram dataframe with weighted sentiment scores of sentiword\n",
    "\n",
    "for idx,sent_word_list in enumerate(sent_score_word_new):\n",
    "    for sent_word in sent_word_list:\n",
    "        if sent_word[0] in uni_df.columns:\n",
    "            uni_df.loc[idx,sent_word[0]] = (uni_df.loc[idx,sent_word[0]] + sent_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1474)"
      ]
     },
     "execution_count": 1510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_df = uni_df.add_suffix('_without_tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_uni_df = reduced_uni_df.add_suffix('_without_tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amazon unigram lexicon\n",
    "\n",
    "f = open('opinion-lexicon-English/Amazon-laptops-electronics-reviews-unigrams.txt', 'r',encoding = \"ISO-8859-1\")\n",
    "domain_specific_lex = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yelp unigram lexicon\n",
    "f = open('opinion-lexicon-English/Yelp-restaurant-reviews-unigrams.txt', 'r',encoding = \"ISO-8859-1\")\n",
    "domain_specific_lex = f.read().splitlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_score_list = {}\n",
    "lex_list = []\n",
    "for lexes in domain_specific_lex:\n",
    "        splitted_lex = lexes.split(',')\n",
    "        lex_score_list[splitted_lex[0]] = splitted_lex[1]\n",
    "        lex_list.append(splitted_lex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiWeightsLex(words):\n",
    "    tagged_word = []\n",
    "    #tagged = pos_tag(words)\n",
    "    #print(tagged)\n",
    "    idx=-1\n",
    "   \n",
    "    prevIndex = -1\n",
    "    \n",
    "    #for word, tag in tagged:\n",
    "        #wn_tag = penn_to_wn(tag)\n",
    "        #if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV,wn.VERB):\n",
    "            #continue\n",
    "    for word in words:\n",
    "        sentiment = 0.0\n",
    "        negIndex = []\n",
    "        idx = idx + 1\n",
    "        if word in lex_list:\n",
    "            sentiment = float(lex_score_list[word])\n",
    "        \n",
    "        negIndex = polarityShifter(word, idx, negIndex)\n",
    "\n",
    "        if(idx in negIndex and prevIndex != idx - 1):\n",
    "            prevIndex = idx\n",
    "            sentiment *= -1\n",
    "            #print(word, sentiment, idx)\n",
    "            \n",
    "        tagged_word.append([word,sentiment,idx])\n",
    "        \n",
    "    return tagged_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_score_lex = [] \n",
    "for token in word_token_reduced:\n",
    "    senti_score_lex.append(sentiWeightsLex(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 0.0, 0],\n",
       " ['reccomend', 1.159, 1],\n",
       " ['fried', 0.255, 2],\n",
       " ['pork', 0.577, 3],\n",
       " ['dumplings', 0.522, 4],\n",
       " ['orange', 0.363, 5],\n",
       " ['chicken/beef', -0.045, 6]]"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_score_lex[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bit of modification\n",
    "\n",
    "def getScoreForSentimentsLex(feature_columns_sentiword,sent_score_word):\n",
    "    my_df= []\n",
    "    for senti in sent_score_word:\n",
    "        total_pos = 0\n",
    "        total_neg = 0\n",
    "        sum_of_scores = 0\n",
    "        maximum_token_score = 0\n",
    "        minimum_token_score = 0\n",
    "        for se in senti:\n",
    "            if se[1] > 0:\n",
    "                total_pos += se[1]\n",
    "\n",
    "            if se[1] < 0:\n",
    "                total_neg += se[1]\n",
    "\n",
    "            sum_of_scores = sum_of_scores + se[1]\n",
    "\n",
    "            if se[1] > maximum_token_score:\n",
    "                maximum_token_score = se[1]\n",
    "\n",
    "            if se[1] < minimum_token_score:\n",
    "                minimum_token_score = se[1]\n",
    "\n",
    "        #print(number_of_pos)\n",
    "\n",
    "        d = {\n",
    "            feature_columns_sentiword[0] : total_pos,  \n",
    "            feature_columns_sentiword[1] : total_neg,\n",
    "            feature_columns_sentiword[2] : sum_of_scores,\n",
    "            feature_columns_sentiword[3] : maximum_token_score,\n",
    "            feature_columns_sentiword[4] : minimum_token_score\n",
    "        }\n",
    "        my_df.append(d)\n",
    "\n",
    "    my_df = pd.DataFrame(my_df)\n",
    "    return my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating unigram dataframe with weighted sentiment scores of sentiword\n",
    "\n",
    "for idx,sent_word_list in enumerate(senti_score_lex):\n",
    "    for sent_word in sent_word_list:\n",
    "        if sent_word[0] in uni_df.columns:\n",
    "            uni_df.loc[idx,sent_word[0]] = (uni_df.loc[idx,sent_word[0]] + sent_word[1])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1474)"
      ]
     },
     "execution_count": 1520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with absolute sum less than 0.001\n",
    "cols_with_less_than_abs_sum = [col for col in uni_df.columns \n",
    "                                 if abs(uni_df[col].sum()) < 2]\n",
    "reduced_uni_df = uni_df.drop(cols_with_less_than_abs_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 295)"
      ]
     },
     "execution_count": 1522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_uni_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum token score lex_test</th>\n",
       "      <th>minimum token score lex_test</th>\n",
       "      <th>sum of scores lex_test</th>\n",
       "      <th>total negatives lex_test</th>\n",
       "      <th>total positives lex_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.159</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>2.831</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>2.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.265</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>1.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.448</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>4.816</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>5.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.262</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>3.405</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>4.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>-1.526</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maximum token score lex_test  minimum token score lex_test  \\\n",
       "0                         1.159                        -0.045   \n",
       "1                         0.600                        -0.133   \n",
       "2                         1.448                        -0.202   \n",
       "3                         2.262                        -0.274   \n",
       "4                         0.150                        -0.485   \n",
       "\n",
       "   sum of scores lex_test  total negatives lex_test  total positives lex_test  \n",
       "0                   2.831                    -0.045                     2.876  \n",
       "1                   1.265                    -0.133                     1.398  \n",
       "2                   4.816                    -0.601                     5.417  \n",
       "3                   3.405                    -0.749                     4.154  \n",
       "4                  -1.340                    -1.526                     0.186  "
      ]
     },
     "execution_count": 1523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns_sentiword_lex = ['total positives lex_test','total negatives lex_test','sum of scores lex_test','maximum token score lex_test','minimum token score lex_test']\n",
    "\n",
    "\n",
    "my_df_lex = getScoreForSentimentsLex(feature_columns_sentiword_lex,senti_score_lex)\n",
    "\n",
    "my_df_lex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_sentiword = ['number of positives_test','number of negatives_test','sum of scores_test','maximum token score_test','minimum token score_test']\n",
    "\n",
    "my_df_senti = getScoreForSentiments(feature_columns_sentiword,sent_score_word_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_sentiword_liu = ['number of positives liu_test','number of negatives liu_test','sum of scores liu_test','maximum token score liu_test','minimum token score liu_test']\n",
    "\n",
    "\n",
    "my_df_liu = getScoreForSentiments(feature_columns_sentiword_liu,sent_score_word_liu_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1526,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_sentiword_mpqa = ['number of positives mpqa_test','number of negatives mpqa_test','sum of scores mpqa_test','maximum token score mpqa_test','minimum token score mpqa_test']\n",
    "\n",
    "\n",
    "my_df_mpqa = getScoreForSentiments(feature_columns_sentiword_mpqa,sent_score_word_mpqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 5)"
      ]
     },
     "execution_count": 1527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df_liu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list_senti = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9--28'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[1,\" term_location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[\" text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_text_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2203"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2063"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_main) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5752"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_list_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_list_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = CountVectorizer(vocabulary=vocab_list_set)\n",
    "#cv.fit_transform(train_data[\" text\"]).toarray()\n",
    "#cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23619"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 5752)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_term_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5742</th>\n",
       "      <th>5743</th>\n",
       "      <th>5744</th>\n",
       "      <th>5745</th>\n",
       "      <th>5746</th>\n",
       "      <th>5747</th>\n",
       "      <th>5748</th>\n",
       "      <th>5749</th>\n",
       "      <th>5750</th>\n",
       "      <th>5751</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  5752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   5742  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   5743  5744  5745  5746  5747  5748  5749  5750  5751  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 5752 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_term_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 331)"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx,ngrm in enumerate(ngram_set):\n",
    "#    print('ngram: {0}\\n'.format(ngrm))\n",
    "#    print('ngram.shape: {0}'.format(ngrm.shape))\n",
    "#    print('vectorizer.vocabulary_: {0}'.format(vectorizers[idx].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['maximum token score liu_test' 'minimum token score liu_test'\n 'number of negatives liu_test' 'number of positives liu_test'\n 'sum of scores liu_test'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1529-87563fef43d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_mix_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_mix_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_df_liu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data_mix_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_mix_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_df_senti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data_mix_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_mix_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_df_mpqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train_data_mix_back = train_data_mix_back.drop(my_df_lex.columns,axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['maximum token score liu_test' 'minimum token score liu_test'\n 'number of negatives liu_test' 'number of positives liu_test'\n 'sum of scores liu_test'] not contained in axis"
     ]
    }
   ],
   "source": [
    "train_data_mix_back = train_data_mix_back.drop(my_df_liu.columns,axis=1)\n",
    "train_data_mix_back = train_data_mix_back.drop(my_df_senti.columns,axis=1)\n",
    "train_data_mix_back = train_data_mix_back.drop(my_df_mpqa.columns,axis=1)\n",
    "#train_data_mix_back = train_data_mix_back.drop(my_df_lex.columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_mix_back = train_data_mix_back.drop(my_df_senti.columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mix =[]\n",
    "train_data_mix_back = my_df_liu.join(train_data_mix_back)\n",
    "#train_data_mix = my_df_liu.join(my_df_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 1434)"
      ]
     },
     "execution_count": 1533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mix_back.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mix_back = train_data_mix_back.join(my_df_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_mix = train_data_mix.join(my_df_liu,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mix_back = train_data_mix_back.join(my_df_mpqa,lsuffix='_left', rsuffix='_right')\n",
    "#train_data_mix = train_data_mix.join(my_df_mpqa,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 668)"
      ]
     },
     "execution_count": 1425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_uni_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_mix = reduced_uni_df.join(train_data_mix,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 683)"
      ]
     },
     "execution_count": 1427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mix = reduced_X_train_tagged.join(train_data_mix,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mix_back = train_data_mix_back.join(my_df_lex,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 1439)"
      ]
     },
     "execution_count": 1430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train_data_mix = train_data_mix.join(train_data_mix_back,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00_nn</th>\n",
       "      <th>100_cd</th>\n",
       "      <th>10_cd</th>\n",
       "      <th>15_cd</th>\n",
       "      <th>1_cd</th>\n",
       "      <th>20_cd</th>\n",
       "      <th>25_cd</th>\n",
       "      <th>2_cd</th>\n",
       "      <th>30_cd</th>\n",
       "      <th>3_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>maximum token score_test</th>\n",
       "      <th>minimum token score_test</th>\n",
       "      <th>number of negatives_test</th>\n",
       "      <th>number of positives_test</th>\n",
       "      <th>sum of scores_test</th>\n",
       "      <th>maximum token score mpqa_test</th>\n",
       "      <th>minimum token score mpqa_test</th>\n",
       "      <th>number of negatives mpqa_test</th>\n",
       "      <th>number of positives mpqa_test</th>\n",
       "      <th>sum of scores mpqa_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00_nn  100_cd  10_cd  15_cd  1_cd  20_cd  25_cd  2_cd  30_cd  3_cd  \\\n",
       "0    0.0     0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "1    0.0     0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "2    0.0     0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "3    0.0     0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "4    0.0     0.0    0.0    0.0   0.0    0.0    0.0   0.0    0.0   0.0   \n",
       "\n",
       "            ...             maximum token score_test  \\\n",
       "0           ...                                0.250   \n",
       "1           ...                                0.625   \n",
       "2           ...                                0.250   \n",
       "3           ...                                0.250   \n",
       "4           ...                                0.125   \n",
       "\n",
       "   minimum token score_test  number of negatives_test  \\\n",
       "0                    -1.250                         1   \n",
       "1                    -0.625                         2   \n",
       "2                    -0.625                         2   \n",
       "3                    -0.625                         2   \n",
       "4                    -1.250                         2   \n",
       "\n",
       "   number of positives_test  sum of scores_test  \\\n",
       "0                         1              -1.000   \n",
       "1                         5               0.875   \n",
       "2                         3              -0.250   \n",
       "3                         2              -0.250   \n",
       "4                         2              -1.125   \n",
       "\n",
       "   maximum token score mpqa_test  minimum token score mpqa_test  \\\n",
       "0                            0.0                           -1.0   \n",
       "1                            1.0                            0.0   \n",
       "2                            1.0                            0.0   \n",
       "3                            1.0                            0.0   \n",
       "4                            1.0                            0.0   \n",
       "\n",
       "   number of negatives mpqa_test  number of positives mpqa_test  \\\n",
       "0                              1                              0   \n",
       "1                              0                              2   \n",
       "2                              0                              3   \n",
       "3                              0                              3   \n",
       "4                              0                              3   \n",
       "\n",
       "   sum of scores mpqa_test  \n",
       "0                     -1.0  \n",
       "1                      1.5  \n",
       "2                      2.0  \n",
       "3                      2.0  \n",
       "4                      2.0  \n",
       "\n",
       "[5 rows x 1439 columns]"
      ]
     },
     "execution_count": 1434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum token score liu_test</th>\n",
       "      <th>minimum token score liu_test</th>\n",
       "      <th>number of negatives liu_test</th>\n",
       "      <th>number of positives liu_test</th>\n",
       "      <th>sum of scores liu_test</th>\n",
       "      <th>00_nn</th>\n",
       "      <th>100_cd</th>\n",
       "      <th>10_cd</th>\n",
       "      <th>15_cd</th>\n",
       "      <th>1_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>maximum token score_test</th>\n",
       "      <th>minimum token score_test</th>\n",
       "      <th>number of negatives_test</th>\n",
       "      <th>number of positives_test</th>\n",
       "      <th>sum of scores_test</th>\n",
       "      <th>maximum token score mpqa_test</th>\n",
       "      <th>minimum token score mpqa_test</th>\n",
       "      <th>number of negatives mpqa_test</th>\n",
       "      <th>number of positives mpqa_test</th>\n",
       "      <th>sum of scores mpqa_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   maximum token score liu_test  minimum token score liu_test  \\\n",
       "0                           0.0                          -1.0   \n",
       "1                           2.0                           0.0   \n",
       "2                           2.0                           0.0   \n",
       "3                           1.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   number of negatives liu_test  number of positives liu_test  \\\n",
       "0                             1                             0   \n",
       "1                             0                             2   \n",
       "2                             0                             1   \n",
       "3                             0                             2   \n",
       "4                             0                             0   \n",
       "\n",
       "   sum of scores liu_test  00_nn  100_cd  10_cd  15_cd  1_cd  \\\n",
       "0                    -1.0    0.0     0.0    0.0    0.0   0.0   \n",
       "1                     3.0    0.0     0.0    0.0    0.0   0.0   \n",
       "2                     2.0    0.0     0.0    0.0    0.0   0.0   \n",
       "3                     2.0    0.0     0.0    0.0    0.0   0.0   \n",
       "4                     0.0    0.0     0.0    0.0    0.0   0.0   \n",
       "\n",
       "            ...             maximum token score_test  \\\n",
       "0           ...                                 0.00   \n",
       "1           ...                                 0.75   \n",
       "2           ...                                 1.50   \n",
       "3           ...                                 0.75   \n",
       "4           ...                                 0.50   \n",
       "\n",
       "   minimum token score_test  number of negatives_test  \\\n",
       "0                     0.000                         0   \n",
       "1                    -0.125                         1   \n",
       "2                    -0.375                         1   \n",
       "3                     0.000                         0   \n",
       "4                    -1.250                         2   \n",
       "\n",
       "   number of positives_test  sum of scores_test  \\\n",
       "0                         0               0.000   \n",
       "1                         2               1.125   \n",
       "2                         1               1.125   \n",
       "3                         5               1.500   \n",
       "4                         1              -0.875   \n",
       "\n",
       "   maximum token score mpqa_test  minimum token score mpqa_test  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.5                           -0.5   \n",
       "2                            1.0                            0.0   \n",
       "3                            0.5                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   number of negatives mpqa_test  number of positives mpqa_test  \\\n",
       "0                              0                              0   \n",
       "1                              2                              1   \n",
       "2                              0                              1   \n",
       "3                              0                              2   \n",
       "4                              0                              0   \n",
       "\n",
       "   sum of scores mpqa_test  \n",
       "0                      0.0  \n",
       "1                     -0.5  \n",
       "2                      1.0  \n",
       "3                      1.0  \n",
       "4                      0.0  \n",
       "\n",
       "[5 rows x 1439 columns]"
      ]
     },
     "execution_count": 1535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mix_back.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train_data_mix = train_data_mix_back.join(train_data_mix_back,lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: '.reindex_axis' is deprecated and will be removed in a future version. Use '.reindex' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#result = pd.concat([train_data_mix_back,train_data_mix],axis=0,join='inner')\n",
    "\n",
    "#result = train_data_mix_back.append(train_data_mix.reindex_axis(train_data_mix_back.columns, 1, fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 1439)"
      ]
     },
     "execution_count": 1435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203,)"
      ]
     },
     "execution_count": 1436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mix_back = train_data_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(train_data_mix, Y,random_state = 0)\n",
    "#example_ids = val_X[\" example_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=683, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 1442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest train\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=683, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "forest_model.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "forest_pred = forest_model.predict(train_data_mix_back)\n",
    "genOutput('Noman_Mulla_Sylvester_Raj_Data-2.txt',example_ids,forest_pred)\n",
    "#accuracy_score(val_Y, forest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.6864813 , 0.68823529, 0.78080808]), array([0.8647343 , 0.26834862, 0.82321619]), array([0.76536611, 0.38613861, 0.80145153]), array([828, 436, 939]))\n",
      "Overal Accuracy\n",
      "0.7290059010440308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#Random Forest using cross validation and confusion matrix\n",
    "forest_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=683, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "predicted = cross_val_predict(forest_model, train_data_mix, Y, cv=10)\n",
    "conf_mat_forest = confusion_matrix(Y,predicted,labels=[-1,0,1])\n",
    "#calclulateF1(conf_mat_forest)\n",
    "#print(calclulateF1(conf_mat_naive))\n",
    "print(precision_recall_fscore_support(Y,predicted))\n",
    "print(\"Overal Accuracy\")\n",
    "print(accuracy_score(Y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-62e7f7e0d2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mxgboost_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgboost_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "xgboost = XGBClassifier(learning_rate= 0.2, n_estimators= 300,max_depth=30)\n",
    "xgboost.fit(train_X,train_Y)\n",
    "xgboost_pred = xgboost.predict(val_X)\n",
    "accuracy_score(val_Y, xgboost_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('bag', BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=99999,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       " ...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=99999,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\n",
    "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
    "         max_samples=1.0, n_estimators=99, n_jobs=1, oob_score=False,\n",
    "         random_state=None, verbose=0, warm_start=False)\n",
    "clf2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=683, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "clf3 = MLPClassifier()\n",
    "\n",
    "vote_model = VotingClassifier(estimators=[('bag', clf1), ('rf', clf2), ('mlp', clf3)], voting='hard')\n",
    "vote_model.fit(train_data_mix,Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 1364 and input n_features is 543.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-503-9c9b06be3259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvote_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvote_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Noman_Mulla_Sylvester_Raj_Data-1.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexample_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvote_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 'hard' voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             maj = np.apply_along_axis(\n\u001b[1;32m    223\u001b[0m                 lambda x: np.argmax(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mpredicted_probabilitiy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m         return self.classes_.take((np.argmax(predicted_probabilitiy, axis=1)),\n\u001b[1;32m    644\u001b[0m                                   axis=0)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    674\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is {0} and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                              \u001b[0;34m\"input n_features is {1}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                              \"\".format(self.n_features_, X.shape[1]))\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;31m# Parallel loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 1364 and input n_features is 543."
     ]
    }
   ],
   "source": [
    "vote_pred = vote_model.predict(train_data_mix)\n",
    "genOutput('Noman_Mulla_Sylvester_Raj_Data-1.txt',example_ids,vote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.7110885 , 0.62992126, 0.78674948]), array([0.8442029 , 0.36697248, 0.80937167]), array([0.7719492 , 0.46376812, 0.79790026]), array([828, 436, 939]))\n",
      "Overal Accuracy\n",
      "0.7349069450748978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "clf1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=99999,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\n",
    "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
    "         max_samples=1.0, n_estimators=49, n_jobs=1, oob_score=False,\n",
    "         random_state=None, verbose=0, warm_start=False)\n",
    "clf2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=683, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "clf3 = MLPClassifier()\n",
    "vote_model = VotingClassifier(estimators=[('bag', clf1), ('rf', clf2), ('mlp', clf3)], voting='hard')\n",
    "predicted = cross_val_predict(vote_model, train_data_mix, Y, cv=10)\n",
    "conf_mat_forest = confusion_matrix(Y,predicted,labels=[-1,0,1])\n",
    "#calclulateF1(conf_mat_forest)\n",
    "#print(calclulateF1(conf_mat_naive))\n",
    "print(precision_recall_fscore_support(Y,predicted))\n",
    "print(\"Overal Accuracy\")\n",
    "print(accuracy_score(Y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm grid search hyper parameter tuning\n",
    "\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def tuneParameters(train_data_mix_fin_n,train_Y):\n",
    "        parameter_candidates = [\n",
    "\n",
    "        \n",
    "        {'C': [1.566,1.691,1.7,1.9,3.56,8,10,15], 'gamma': [0.001,0.00916,0.00888,0.009,0.009785,0.01,1,3],'kernel': ['rbf']},\n",
    "            ]\n",
    "\n",
    "        # Create a classifier object with the classifier and parameter candidates\n",
    "        clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates,cv=10)\n",
    "\n",
    "        # Train the classifier on data1's feature and target data\n",
    "        clf.fit(train_data_mix_fin_n, train_Y)\n",
    "        # View the accuracy score\n",
    "        print('Best score for data:', clf.best_score_) \n",
    "\n",
    "        # View the best parameters for the model found using grid search\n",
    "        print('Best C:',clf.best_estimator_.C) \n",
    "        best_C = clf.best_estimator_.C\n",
    "        print('Best Kernel:',clf.best_estimator_.kernel)\n",
    "        best_kernel = clf.best_estimator_.kernel\n",
    "        print('Best Gamma:',clf.best_estimator_.gamma)\n",
    "        best_gamma = clf.best_estimator_.gamma\n",
    "        print('Best Degree:',clf.best_estimator_.degree)\n",
    "        best_degree = clf.best_estimator_.degree\n",
    "        return best_C,best_kernel,best_gamma,best_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for data: 0.7172038129822969\n",
      "Best C: 15\n",
      "Best Kernel: rbf\n",
      "Best Gamma: 0.01\n",
      "Best Degree: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 'rbf', 0.01, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneParameters(train_data_mix,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849878934624698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7041742286751361"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Library\n",
    "from sklearn import svm\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "# C = [3.1,3.5,3.55,3.981,3.764,3.333]\n",
    "# gamma = [0.01,0.03,0.05,0.055,0.066,0.077,0.091,0.092,0.0933,0.1]\n",
    "model = svm.SVC(kernel='rbf', C=15, gamma=0.01) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_X, train_Y)\n",
    "print(model.score(train_X, train_Y))\n",
    "#Predict Output\n",
    "predicted= model.predict(val_X)\n",
    "accuracy_score(val_Y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.71012931, 0.5613079 , 0.79955947]), array([0.79589372, 0.47247706, 0.77316294]), array([0.75056948, 0.51307597, 0.78613969]), array([828, 436, 939]))\n",
      "Overal Accuracy\n",
      "0.7221970040853382\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm.SVC(kernel='rbf',  C=15, gamma=0.015) \n",
    "predicted = cross_val_predict(svm_model, train_data_mix, Y, cv=10)\n",
    "conf_mat_forest = confusion_matrix(Y,predicted,labels=[-1,0,1])\n",
    "#calclulateF1(conf_mat_forest)\n",
    "#print(calclulateF1(conf_mat_naive))\n",
    "print(precision_recall_fscore_support(Y,predicted))\n",
    "print(\"Overal Accuracy\")\n",
    "print(accuracy_score(Y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOutput(output_file, example_ids, predicted):\n",
    "    output_file = open(output_file,'w')\n",
    "    for i in range(0, len(predicted)):\n",
    "        output_file.write(str(example_ids[i]) +\";;\"+ str(predicted[i])+\"\\n\")\n",
    "        #print(predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
