{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training bigram tagger\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def build_backoff_tagger(train_sents):\n",
    "    t0 = nltk.DefaultTagger('NN')\n",
    "    t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "    t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_tagger = build_backoff_tagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9125751765470128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2333_1</td>\n",
       "      <td>Obviously one of the most important features o...</td>\n",
       "      <td>human interface</td>\n",
       "      <td>69--84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1805_1</td>\n",
       "      <td>Good for every day computing and web browsing.</td>\n",
       "      <td>every day computing</td>\n",
       "      <td>9--28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2782_2</td>\n",
       "      <td>while the keyboard itself is alright[comma] th...</td>\n",
       "      <td>mouse command buttons</td>\n",
       "      <td>115--136</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1385_0</td>\n",
       "      <td>Again[comma] the same problem[comma] the right...</td>\n",
       "      <td>right speaker</td>\n",
       "      <td>29--42</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1423_0</td>\n",
       "      <td>My problem was with DELL Customer Service.</td>\n",
       "      <td>DELL Customer Service</td>\n",
       "      <td>20--41</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text  \\\n",
       "0     2333_1  Obviously one of the most important features o...   \n",
       "1     1805_1     Good for every day computing and web browsing.   \n",
       "2     2782_2  while the keyboard itself is alright[comma] th...   \n",
       "3     1385_0  Again[comma] the same problem[comma] the right...   \n",
       "4     1423_0         My problem was with DELL Customer Service.   \n",
       "\n",
       "             aspect_term  term_location   class  \n",
       "0        human interface         69--84       0  \n",
       "1    every day computing          9--28       1  \n",
       "2  mouse command buttons       115--136      -1  \n",
       "3          right speaker         29--42      -1  \n",
       "4  DELL Customer Service         20--41      -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading train data\n",
    "import pandas as pd\n",
    "train_file_path = \"project_2_train/project_2_train/dara 1_train.csv\"\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = train_data[\" text\"]\n",
    "new_text=[]\n",
    "for idx,text_record in enumerate(text_data):\n",
    "    current_text = text_data[idx].replace(\"[comma]\", \",\")\n",
    "    #current_text = current_text[:int(locations[0])] + \"<aspect>\" + current_text[int(locations[1]):]\n",
    "    new_text.append([current_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_aspect=[]\n",
    "for idx,text_record in enumerate(new_text):\n",
    "    aspect_loc = train_data.loc[idx,\" term_location\"]\n",
    "    locations = aspect_loc.split(\"--\")\n",
    "    current_text = text_record[0]\n",
    "    current_text = current_text[:int(locations[0])] + \"<aspect>\" + current_text[int(locations[1]):]\n",
    "    new_text_aspect.append(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting words in context 0f 5 from target term\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "sent_list=[]\n",
    "\n",
    "remove_list = [\",\",\".\",\".)\",\"..)\",\").\",\"?\",\"!\"]\n",
    "    \n",
    "    \n",
    "for idx,text_word in enumerate(new_text_aspect):\n",
    "    locations = train_data.loc[idx,\" term_location\"].split(\"--\")\n",
    "    sent = text_word\n",
    "    sent_left = sent[:int(locations[0])]\n",
    "    #token_left = nltk.word_tokenize(sent_left)\n",
    "    #print(token_left)\n",
    "    #bigram_left = nltk.bigrams(token_left)\n",
    "    #bigram_left = *map(' '.join, bigrm)\n",
    "    sent_right = sent[int(locations[0])+8:]\n",
    "    #print(sent_right)\n",
    "    \n",
    "    #token_right = nltk.word_tokenize(sent_right)\n",
    "    if sent_right not in remove_list:\n",
    "        sent_surf = ' '.join(sent_left.split()[-5:])+' '+' '.join(sent_right.split()[:5])\n",
    "    else:\n",
    "        sent_surf = ' '.join(sent_left.split()[-5:])\n",
    "    #print(sent_surf)\n",
    "    sent_list.append([sent_surf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer, WordPunctTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "features_uni=[]\n",
    "#stop_list = stopwords.words('english') +['.',',',')','?','!','(','-',':','The','I','It','We',\"'\",'They','My','But','us']\n",
    "\n",
    "#stops = set(stop_list)\n",
    "for line in sent_list:\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = nltk.word_tokenize(line[0])\n",
    "    #print(tokens)\n",
    "    #stemmer = PorterStemmer()\n",
    "    #bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "    #bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)\n",
    "    #bigrams = ngrams(line,2)\n",
    "    #for bigram_tuple in bigrams:\n",
    "    #    x = \"%s %s\" % bigram_tuple\n",
    "    #    tokens.append(x)\n",
    "    tagged_tokens = ngram_tagger.tag(tokens)\n",
    "    #result = [b for b in nltk.bigrams(line) if b[0] not in stops and b[1] not in stops]\n",
    "    #new_token = []\n",
    "    #for token in tokens:\n",
    "        #if token not in stops:\n",
    "     #       new_token.append(token)\n",
    "    features_uni.append(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tagged_Sent=[]\n",
    "for feature in features_uni:\n",
    "    sent = \"\"\n",
    "    for tuples in feature:\n",
    "        sent = sent +\" \" +tuples[0]+\"_\"+tuples[1]\n",
    "    \n",
    "    new_tagged_Sent.append(sent.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_df_tagged = pd.DataFrame({'text_tagged':new_tagged_Sent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any_DTI computer_NN is_BEZ the_AT ``_``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good_JJ for_IN and_CC web_NN browsing_VBG ._.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hollow_JJ sound_NN when_WRB using_VBG the_AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Again_RB ,_, the_AT same_AP problem_NN ,_, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My_PP$ problem_NN was_BEDZ with_IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_tagged\n",
       "0            any_DTI computer_NN is_BEZ the_AT ``_``\n",
       "1      Good_JJ for_IN and_CC web_NN browsing_VBG ._.\n",
       "2       hollow_JJ sound_NN when_WRB using_VBG the_AT\n",
       "3  Again_RB ,_, the_AT same_AP problem_NN ,_, the...\n",
       "4                 My_PP$ problem_NN was_BEDZ with_IN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df_tagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words with pos tage\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_bag_tagged = count_vect.fit_transform(text_df_tagged[\"text_tagged\"])\n",
    "X_term_freq_tagged = pd.DataFrame(X_train_bag_tagged.toarray(),columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_nn</th>\n",
       "      <th>10</th>\n",
       "      <th>100_cd</th>\n",
       "      <th>1024_cd</th>\n",
       "      <th>10_cd</th>\n",
       "      <th>10th_nn</th>\n",
       "      <th>11_nn</th>\n",
       "      <th>13_cd</th>\n",
       "      <th>14_cd</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>yes_rb</th>\n",
       "      <th>yet_cc</th>\n",
       "      <th>yet_rb</th>\n",
       "      <th>you_nn</th>\n",
       "      <th>you_ppo</th>\n",
       "      <th>you_ppss</th>\n",
       "      <th>your_pp</th>\n",
       "      <th>yourself_ppl</th>\n",
       "      <th>yummy_nn</th>\n",
       "      <th>zero_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_nn  10  100_cd  1024_cd  10_cd  10th_nn  11_nn  13_cd  14_cd  15  \\\n",
       "0     0   0       0        0      0        0      0      0      0   0   \n",
       "1     0   0       0        0      0        0      0      0      0   0   \n",
       "2     0   0       0        0      0        0      0      0      0   0   \n",
       "3     0   0       0        0      0        0      0      0      0   0   \n",
       "4     0   0       0        0      0        0      0      0      0   0   \n",
       "\n",
       "    ...     yes_rb  yet_cc  yet_rb  you_nn  you_ppo  you_ppss  your_pp  \\\n",
       "0   ...          0       0       0       0        0         0        0   \n",
       "1   ...          0       0       0       0        0         0        0   \n",
       "2   ...          0       0       0       0        0         0        0   \n",
       "3   ...          0       0       0       0        0         0        0   \n",
       "4   ...          0       0       0       0        0         0        0   \n",
       "\n",
       "   yourself_ppl  yummy_nn  zero_cd  \n",
       "0             0         0        0  \n",
       "1             0         0        0  \n",
       "2             0         0        0  \n",
       "3             0         0        0  \n",
       "4             0         0        0  \n",
       "\n",
       "[5 rows x 2456 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_term_freq_tagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_bag_tagged)\n",
    "#X_train_tfidf.shape\n",
    "X_tfidf_tagged = pd.DataFrame(X_train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with sum less than 2\n",
    "cols_with_less_than_25 = [col for col in X_tfidf_tagged.columns \n",
    "                                 if abs(X_tfidf_tagged[col].sum()) < 1]\n",
    "reduced_X_train_tagged = X_tfidf_tagged.drop(cols_with_less_than_25, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>2439</th>\n",
       "      <th>2440</th>\n",
       "      <th>2443</th>\n",
       "      <th>2446</th>\n",
       "      <th>2447</th>\n",
       "      <th>2448</th>\n",
       "      <th>2450</th>\n",
       "      <th>2451</th>\n",
       "      <th>2452</th>\n",
       "      <th>2455</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1071 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     4     7     15    19    20    22    25    30    ...   2439  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   2440  2443  2446  2447  2448  2450  2451  2452  2455  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1071 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_X_train_tagged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
